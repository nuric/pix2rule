# pix2rule

From pixels to symbolic rule learning

## Project Structure

The project contains some reusable parts and some that are integrated into the local repository structure. Mainly it revolves around the following folders and files:

- **components:** Contains reusable layers and operations. Every component is unit tested and self-isolated. It contains things layers such as CNN backbones and object selection. Note that not all components are used in the final models.
- **datasets:** Describes the available datasets, how to generate and load them. Every dataset gets its own module and the `__init__.py` keeps track of them.
- **models:** Similar to datasets, it contains models that often use the available components. They are full trainable models and use the `build_model` function to create them. The module init file keeps track of available models.
- **utils:** Contains utility functions and classes such as custom callbacks. Some are tested such as dictionary hashing. Utility functions are also self-contained and can be used in other projects.
- **configlib:** The mini configuration library that handles multiple file `argparse` flags. It collects all the arguments, parses them and provides extra functionality such as reading in a JSON file. Utilities and components do not use this library to make them self-contained.
- **reportlib:** The mini tensor and model reporting library for extracting out intermediate tensors and representations. It provides two main parts: `report_tensor` and `ReportLayer` which store passed tensor values to a global dictionary when run with `create_report`. Note this requires the model to be run in eager mode so the intermediate tensors are evaluated.
- **train.py:** The entry point for running experiments. One can find out all moving parts by running `python3 train.py -h`. It will list all collected flags. It loads the dataset, create the model, sets up mlflow and trains the model.
- **experiments.py:** A script to generate experiment configurations and pre-generated required datasets. It will list all experiment configurations and write them into a file to run later.
- **condor_run.py:** Takes the experiment configurations generated by experiments and runs them using the department HTCondor cluster.
